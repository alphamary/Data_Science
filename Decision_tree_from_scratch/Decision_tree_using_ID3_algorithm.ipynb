{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Evaluation With Decision Tree Using ID3 Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"Car Evaluation Database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX (M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.).\"**\n",
    "\n",
    "\n",
    "We have a dataset that has four classes and six attributes. We will treat all the values in the dataset as categorical and won't transform them into numerical values. This is a scratch implementation of decision tree and we won't be using any packages to do the actual computation. \n",
    "\n",
    "I have used a dictionary to capture the tree, and the class method doesn't return the tree. Feel free to change the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety class_a\n",
       "0  vhigh  vhigh     2       2    small    low   unacc\n",
       "1  vhigh  vhigh     2       2    small    med   unacc\n",
       "2  vhigh  vhigh     2       2    small   high   unacc\n",
       "3  vhigh  vhigh     2       2      med    low   unacc\n",
       "4  vhigh  vhigh     2       2      med    med   unacc\n",
       "5  vhigh  vhigh     2       2      med   high   unacc\n",
       "6  vhigh  vhigh     2       2      big    low   unacc\n",
       "7  vhigh  vhigh     2       2      big    med   unacc\n",
       "8  vhigh  vhigh     2       2      big   high   unacc\n",
       "9  vhigh  vhigh     2       4    small    low   unacc"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the data as a pandas dataframe\n",
    "import pandas as pd\n",
    "# defining the table header info\n",
    "header_row = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class_a\"]\n",
    "df = pd.read_csv(\"car.csv\", delimiter=\",\", names=header_row) # importing the csv as a dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unacc: 1210\n",
      "acc: 384\n",
      "vgood: 65\n",
      "good: 69\n",
      "total: 1728\n"
     ]
    }
   ],
   "source": [
    "# class distribution of the dataset\n",
    "from collections import Counter\n",
    "count  = Counter(df[\"class_a\"])\n",
    "total = 0\n",
    "for i in count:\n",
    "    print(\"{}: {}\".format(i, count[i]))\n",
    "    total += count[i]\n",
    "print(\"total: {}\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we are going to split the dataset into training set and test set. \n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df[\"class_a\"]\n",
    "X = df.drop([\"class_a\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1209, 6)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the size of training set\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have to calculate the entropy of the dataset mainly the training dataset. For that, we will create a function that will output the entropy value of a given dataset. For more information on entropy please search online.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total entropy of the training set is 0.592048932418\n"
     ]
    }
   ],
   "source": [
    "# since we have four classes we will use log base 4 to normalize the entropy value\n",
    "from math import log\n",
    "def entropy(a=0, b=0, c=0, d=0):\n",
    "    total = [a, b, c, d]\n",
    "    r = 0\n",
    "    for i in total:\n",
    "        if i != 0: # since log 0 is undefined\n",
    "            r += -((i/sum(total))*log(i/sum(total), 4))\n",
    "    return r\n",
    "\n",
    "# entropy of the entire training data set (y)\n",
    "entro_set = entropy(*[i for i in Counter(y_train).values()])\n",
    "print(\"The total entropy of the training set is {}\".format(entro_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we have to split the dataset into their attributes and compute the total gain in each case. We will continue the process recursively to establish all the nodes and branches.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is our main class\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class decision_tree(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, class_col=\"class_a\"):\n",
    "        self.class_col = class_col\n",
    "        \n",
    "    @staticmethod\n",
    "    def score(split_s, entro, total):\n",
    "        # here we calculate the entropy of each branch and add them proportionally\n",
    "        # to get the total entropy of the attribute\n",
    "        entro_set = [entropy(*i) for i in split_s] # entropy of each branch\n",
    "        f = lambda x, y: (sum(x)/total) * y \n",
    "        result = [f(i, j) for i, j in zip(split_s, entro_set)]\n",
    "        return entro - sum(result)\n",
    "        \n",
    "    @staticmethod\n",
    "    def split_set(header, dataset, class_col):\n",
    "        # here we split the attribute into each branch and count the classes\n",
    "        df = pd.DataFrame(dataset.groupby([header, class_col])[class_col].count())\n",
    "        result = []\n",
    "        for i in Counter(dataset[header]).keys():\n",
    "            result.append(df.loc[i].values)\n",
    "            \n",
    "        return result\n",
    "            \n",
    "    \n",
    "    @classmethod\n",
    "    def node(cls, dataset, class_col):\n",
    "        entro = entropy(*[i for i in Counter(dataset[class_col]).values()])\n",
    "        result = {} # this will store the total gain of each attribute\n",
    "        for i in dataset.columns:\n",
    "            if i != class_col:\n",
    "                split_s = cls.split_set(i, dataset, class_col) \n",
    "                g_score = cls.score(split_s, entro, total=len(dataset)) # total gain of an attribute\n",
    "                result[i] = g_score\n",
    "        return max(result, key=result.__getitem__)\n",
    "            \n",
    "    \n",
    "    @classmethod\n",
    "    def recursion(cls, dataset, tree, class_col):\n",
    "        n = cls.node(dataset, class_col) # finding the node that sits as the root\n",
    "        branchs = [i for i in Counter(dataset[n])]\n",
    "        tree[n] = {}\n",
    "        for i in branchs: # we are going to iterate over the branches and create the subsequent nodes\n",
    "            br_data = dataset[dataset[n] == i] # spliting the data at each branch\n",
    "            if entropy(*[i for i in Counter(br_data[class_col]).values()]) != 0:\n",
    "                tree[n][i] = {}\n",
    "                cls.recursion(br_data, tree[n][i], class_col)\n",
    "            else:\n",
    "                r = Counter(br_data[class_col])\n",
    "                tree[n][i] = max(r, key=r.__getitem__) # returning the final class attribute at the end of tree\n",
    "        return\n",
    "                \n",
    "    @classmethod\n",
    "    def pred_recur(cls, tupl, t):\n",
    "        if type(t) is int:\n",
    "            return \"NaN\" # assigns NaN when the path is missing for a given test case\n",
    "        elif type(t) is not dict:\n",
    "            return t\n",
    "        index = {'buying': 1, 'maint': 2, 'doors': 3, 'persons': 4, 'lug_boot': 5, 'safety': 6}\n",
    "        for i in t.keys():\n",
    "            if i in index.keys():\n",
    "                r = cls.pred_recur(tupl, t[i].get(tupl[index[i]], 0))\n",
    "        return r\n",
    "\n",
    "    # main prediction function\n",
    "    def predict(self, test):\n",
    "        result = []\n",
    "        for i in test.itertuples():\n",
    "                result.append(decision_tree.pred_recur(i, self.tree_))\n",
    "        return pd.Series(result) # returns the predicted classes of a test dataset in pandas Series\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y): # this is our main method which we will call to build the decision tree\n",
    "        class_col = self.class_col # the class_col takes the column name of class attribute\n",
    "        dataset = X.assign(class_a=y)\n",
    "        self.tree_ = {} # we will capture all the decision criteria in a python dictionary\n",
    "        decision_tree.recursion(dataset, self.tree_, class_col)\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decision_tree(class_col='class_a')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = decision_tree() # creating a instance for the decision_tree class\n",
    "model.fit(X_train, y_train) # calling the fit method to create the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89210019267822738"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the accuracy score under train-test-split\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we are going to implement a K-fold cross validation test to get a more generalized accuracy score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88        0.84        0.888       0.856       0.856       0.888\n",
      "  0.83739837  0.80487805  0.74796748  0.86885246  0.8442623   0.81967213\n",
      "  0.8442623   0.78512397]\n"
     ]
    }
   ],
   "source": [
    "# After numerous iteration K = 14 has yeilded the best generalized mean for our model. The K is the number of folds or \n",
    "# groups the dataset is divided. A low K can have biases and very high K is computationaly expensive. \n",
    "# A trade off is there and we have to select a optimal value, here the value is 14. \n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model, X, y, cv=14, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value for K-fold cross validation test that best explains our model is 0.8400297892649317\n"
     ]
    }
   ],
   "source": [
    "print(\"The mean value for K-fold cross validation test that best explains our model is {}\".format(scores.mean())) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
