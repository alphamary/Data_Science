{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Survival Status of Breast Cancer Patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " “The dataset contains cases from a study that was conducted between 1958 and 1970 at the University of Chicago's Billings Hospital on the survival of patients who had undergone surgery for breast Cancer.”\n",
    " \n",
    "There are four variables in the dataset, including the dependent variable. We are going to use age, operation_year and axillary_nodes_count to build a classifier that can predict the likelihood of survival of less than five years or more than five years. \n",
    " \n",
    "The default dataset has two categories, 1 and 2 (1 = the patient survived 5 years or longer\n",
    "2 = the patient died within 5 year) . We are going to change that into the form 0 and 1 for probability computation, 1 being the longer survival period. \n",
    "\n",
    "We have to first prepare the data for computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# importing the dataset as a pandas dataframe\n",
    "df = pd.read_csv(\"haberman.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'operation_year', 'axillary_nodes_count', 'survival_status'], dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the columns of the dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing data in the dataset, so there's no need to drop any row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2\n",
       "0    1  0\n",
       "1    1  0\n",
       "2    1  0\n",
       "3    1  0\n",
       "4    1  0\n",
       "5    1  0\n",
       "6    1  0\n",
       "7    0  1\n",
       "8    0  1\n",
       "9    1  0\n",
       "10   1  0\n",
       "11   1  0\n",
       "12   1  0\n",
       "13   1  0\n",
       "14   1  0\n",
       "15   1  0\n",
       "16   1  0\n",
       "17   1  0\n",
       "18   1  0\n",
       "19   1  0\n",
       "20   1  0\n",
       "21   1  0\n",
       "22   1  0\n",
       "23   1  0\n",
       "24   0  1\n",
       "25   1  0\n",
       "26   1  0\n",
       "27   1  0\n",
       "28   1  0\n",
       "29   1  0\n",
       "..  .. ..\n",
       "276  1  0\n",
       "277  1  0\n",
       "278  1  0\n",
       "279  1  0\n",
       "280  1  0\n",
       "281  0  1\n",
       "282  1  0\n",
       "283  1  0\n",
       "284  1  0\n",
       "285  0  1\n",
       "286  0  1\n",
       "287  1  0\n",
       "288  1  0\n",
       "289  1  0\n",
       "290  1  0\n",
       "291  1  0\n",
       "292  1  0\n",
       "293  0  1\n",
       "294  1  0\n",
       "295  1  0\n",
       "296  1  0\n",
       "297  1  0\n",
       "298  1  0\n",
       "299  0  1\n",
       "300  1  0\n",
       "301  1  0\n",
       "302  1  0\n",
       "303  1  0\n",
       "304  0  1\n",
       "305  0  1\n",
       "\n",
       "[306 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have to update the survival status to binary 0 and 1. Inorder to do this we will create dummy variables\n",
    "pd.get_dummies(df.survival_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we are going to set the column survival_count with the new values\n",
    "\n",
    "df[\"survival_status\"] = pd.get_dummies(df.survival_status)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>operation_year</th>\n",
       "      <th>axillary_nodes_count</th>\n",
       "      <th>survival_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  operation_year  axillary_nodes_count  survival_status\n",
       "0   30              64                     1                1\n",
       "1   30              62                     3                1\n",
       "2   30              65                     0                1\n",
       "3   31              59                     2                1\n",
       "4   31              65                     4                1\n",
       "5   33              58                    10                1\n",
       "6   33              60                     0                1\n",
       "7   34              59                     0                0\n",
       "8   34              66                     9                0\n",
       "9   34              58                    30                1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the survival status is the dependent variable here\n",
    "y = df[\"survival_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we need to drop the survival_status and operation_year from the dataframe\n",
    "df.drop([\"survival_status\", \"operation_year\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **We have droped the operation_year because it's centered around 63 with an standard deviation of 3. Since most of the data point will lie between one standard deviation, the time span isn't significant enough to show any change in technology. In another test, the operation_year variable has shown to decrease the effectiveness of the model.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>axillary_nodes_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  axillary_nodes_count\n",
       "0   30                     1\n",
       "1   30                     3\n",
       "2   30                     0\n",
       "3   31                     2\n",
       "4   31                     4\n",
       "5   33                    10\n",
       "6   33                     0\n",
       "7   34                     0\n",
       "8   34                     9\n",
       "9   34                    30"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the current dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We won't be scaling the data for this model, because it's not required here.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we will create the training set and test case for comparison later\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't know how much good is good. So any dumb model can achieve high accuracy by just returing the most frequent occuring class in the y_test series. We will calculate the proportion of the most frequent class, and we will lable it null accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    55\n",
       "0    22\n",
       "Name: survival_status, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our class distribution\n",
    "y_test.value_counts()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculaing proportion of ones in the test set, since its clear from the above result \n",
    "# that ones are more than the zeroes.\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Any model that returns all patient survived more than 5 years will be 71% correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating instance model for logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(penalty='l2', C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy score is 0.727\n"
     ]
    }
   ],
   "source": [
    "# now we are going to fit our test data into the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Our accuracy score is {:.3f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our model doesn't look good compared to the nulll accuracy. So we need a better matrics to judge out model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will be using a confusion matrix to understand the nature of errors we have committed. The confusion matrix is a table, here it's 2X2 in dimension, that tells about four things: True Negative (upper left), False Positive (upper right), False Negative ( lower left)  and True Positive ( lower right).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 17],\n",
       "       [ 4, 51]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we are going to isolate the confusion matrix\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we are going to calculate the sensitivity and specificity using the above values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Sensitivity measures how often a positive value gets classified as positive.**\n",
    "\n",
    "** Specificity measures how often a negative value gets classified as negative.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.927272727273\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \", TP / (TP + FN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  0.227272727273\n"
     ]
    }
   ],
   "source": [
    "print(\"Specificity: \", TN / (TN + FP))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# We have to adjust the classifcation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 1 1 1 1]\n",
      "[1 1 1 1 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# we will view the the first 10 predictions for the model to know which probability belongs to which class\n",
    "print(y_pred[0:10])\n",
    "print(model.predict(X_test)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21265053,  0.78734947],\n",
       "       [ 0.19422699,  0.80577301],\n",
       "       [ 0.2192878 ,  0.7807122 ],\n",
       "       [ 0.20012736,  0.79987264],\n",
       "       [ 0.18282461,  0.81717539],\n",
       "       [ 0.7657807 ,  0.2342193 ],\n",
       "       [ 0.20525744,  0.79474256],\n",
       "       [ 0.21016478,  0.78983522],\n",
       "       [ 0.40068576,  0.59931424],\n",
       "       [ 0.2553626 ,  0.7446374 ]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are going to print the predicted probability of the model instance for overview\n",
    "model.predict_proba(X_test)[0:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we will store the predicted probabilities of class 1 in a separate object\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xa74a1cac>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBjMzK/l/bG4s9cAO9FQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa749b08c>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of predicted probabilities\n",
    "plt.hist(y_pred_prob, bins=8)\n",
    "plt.xlim(0, 1)\n",
    "plt.title('Histogram of predicted probabilities')\n",
    "plt.xlabel('Predicted patients living more than 5 years')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We definitly see a negative skewness which explains the high sensitivity in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We have to increase the threshold inorder to decrease the sensitivity\n",
    "from sklearn.preprocessing import binarize\n",
    "y_pred = binarize([y_pred_prob], 0.76)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 12],\n",
       "       [14, 41]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.745454545455\n",
      "Specificity:  0.454545454545\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: \", TP / (TP + FN))\n",
    "print(\"Specificity: \", TN / (TN + FP))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have improved the specificity of the model, thus reducing false positives. We will use AUC to confirm that out model is indeed better than random selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.642148760331\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An AUC above 0.50 proves that the model is better than random chance.** \n",
    "\n",
    "We can use the ROC curve to better judge a threshold for an optimum value, and you can checkout the resource below for futher details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kevin Markham has put up an excellent example of logictic regression, which is very detailed, and I have used his work as a reference. \n",
    "\n",
    "Link to his work below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
